{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iwe_m2d_win_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/altiss/FNO/blob/main/iwe_m2d_win_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SapowXFcfr3"
      },
      "source": [
        "#VIC put here all the new imports that may be needed\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "import h5py\n",
        "import sklearn.metrics\n",
        "import torch.nn as nn\n",
        "from scipy.ndimage import gaussian_filter\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# from utilities3 import *\n",
        "\n",
        "import operator\n",
        "from functools import reduce\n",
        "from functools import partial\n",
        "\n",
        "from timeit import default_timer\n",
        "\n",
        "import os, os.path\n",
        "\n",
        "import torch\n",
        "\n",
        "v = torch.__version__\n",
        "# assert(v[2] == '8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHKPa0CaS47c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95475562-f2d1-495d-9a09-7e426ab46f45"
      },
      "source": [
        "\n",
        "# mount my google drive to access dataset and save model\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive/My Drive/Colab Notebooks\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "neural_solver\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnAf4NpSdQoA"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hg_DT5rrdSUe"
      },
      "source": [
        "#VIC this is the content of: https://github.com/zongyi-li/fourier_neural_operator/blob/master/utilities3.py\n",
        "# it may need to be udpated\n",
        "\n",
        "#################################################\n",
        "#\n",
        "# Utilities\n",
        "#\n",
        "#################################################\n",
        "# reading data\n",
        "class MatReader(object):\n",
        "    def __init__(self, file_path, to_torch=True, to_cuda=False, to_float=True):\n",
        "        super(MatReader, self).__init__()\n",
        "\n",
        "        self.to_torch = to_torch\n",
        "        self.to_cuda = to_cuda\n",
        "        self.to_float = to_float\n",
        "\n",
        "        self.file_path = file_path\n",
        "\n",
        "        self.data = None\n",
        "        self.old_mat = None\n",
        "        self._load_file()\n",
        "\n",
        "    def _load_file(self):\n",
        "        try:\n",
        "            self.data = scipy.io.loadmat(self.file_path)\n",
        "            self.old_mat = True\n",
        "        except:\n",
        "            self.data = h5py.File(self.file_path)\n",
        "            self.old_mat = False\n",
        "\n",
        "    def load_file(self, file_path):\n",
        "        self.file_path = file_path\n",
        "        self._load_file()\n",
        "\n",
        "    def read_field(self, field):\n",
        "        x = self.data[field]\n",
        "\n",
        "        if not self.old_mat:\n",
        "            x = x[()]\n",
        "            x = np.transpose(x, axes=range(len(x.shape) - 1, -1, -1))\n",
        "\n",
        "        if self.to_float:\n",
        "            x = x.astype(np.float32)\n",
        "\n",
        "        if self.to_torch:\n",
        "            x = torch.from_numpy(x)\n",
        "\n",
        "            if self.to_cuda:\n",
        "                x = x.cuda()\n",
        "\n",
        "        return x\n",
        "\n",
        "    def set_cuda(self, to_cuda):\n",
        "        self.to_cuda = to_cuda\n",
        "\n",
        "    def set_torch(self, to_torch):\n",
        "        self.to_torch = to_torch\n",
        "\n",
        "    def set_float(self, to_float):\n",
        "        self.to_float = to_float\n",
        "\n",
        "# normalization, pointwise gaussian\n",
        "class UnitGaussianNormalizer(object):\n",
        "    def __init__(self, x, eps=0.00001):\n",
        "        super(UnitGaussianNormalizer, self).__init__()\n",
        "\n",
        "        # x could be in shape of ntrain*n or ntrain*T*n or ntrain*n*T\n",
        "        self.mean = torch.mean(x, 0)\n",
        "        self.std = torch.std(x, 0)\n",
        "        self.eps = eps\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = (x - self.mean) / (self.std + self.eps)\n",
        "        return x\n",
        "\n",
        "    def decode(self, x, sample_idx=None):\n",
        "        if sample_idx is None:\n",
        "            std = self.std + self.eps # n\n",
        "            mean = self.mean\n",
        "        else:\n",
        "            if len(self.mean.shape) == len(sample_idx[0].shape):\n",
        "                std = self.std[sample_idx] + self.eps  # batch*n\n",
        "                mean = self.mean[sample_idx]\n",
        "            if len(self.mean.shape) > len(sample_idx[0].shape):\n",
        "                std = self.std[:,sample_idx]+ self.eps # T*batch*n\n",
        "                mean = self.mean[:,sample_idx]\n",
        "\n",
        "        # x is in shape of batch*n or T*batch*n\n",
        "        x = (x * std) + mean\n",
        "        return x\n",
        "\n",
        "    def cuda(self):\n",
        "        self.mean = self.mean.cuda()\n",
        "        self.std = self.std.cuda()\n",
        "\n",
        "    def cpu(self):\n",
        "        self.mean = self.mean.cpu()\n",
        "        self.std = self.std.cpu()\n",
        "\n",
        "# normalization, Gaussian\n",
        "class GaussianNormalizer(object):\n",
        "    def __init__(self, x, eps=0.00001):\n",
        "        super(GaussianNormalizer, self).__init__()\n",
        "\n",
        "        self.mean = torch.mean(x)\n",
        "        self.std = torch.std(x)\n",
        "        self.eps = eps\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = (x - self.mean) / (self.std + self.eps)\n",
        "        return x\n",
        "\n",
        "    def decode(self, x, sample_idx=None):\n",
        "        x = (x * (self.std + self.eps)) + self.mean\n",
        "        return x\n",
        "\n",
        "    def cuda(self):\n",
        "        self.mean = self.mean.cuda()\n",
        "        self.std = self.std.cuda()\n",
        "\n",
        "    def cpu(self):\n",
        "        self.mean = self.mean.cpu()\n",
        "        self.std = self.std.cpu()\n",
        "\n",
        "\n",
        "# normalization, scaling by range\n",
        "class RangeNormalizer(object):\n",
        "    def __init__(self, x, low=0.0, high=1.0):\n",
        "        super(RangeNormalizer, self).__init__()\n",
        "        mymin = torch.min(x, 0)[0].view(-1)\n",
        "        mymax = torch.max(x, 0)[0].view(-1)\n",
        "\n",
        "        self.a = (high - low)/(mymax - mymin)\n",
        "        self.b = -self.a*mymax + high\n",
        "\n",
        "    def encode(self, x):\n",
        "        s = x.size()\n",
        "        x = x.view(s[0], -1)\n",
        "        x = self.a*x + self.b\n",
        "        x = x.view(s)\n",
        "        return x\n",
        "\n",
        "    def decode(self, x):\n",
        "        s = x.size()\n",
        "        x = x.view(s[0], -1)\n",
        "        x = (x - self.b)/self.a\n",
        "        x = x.view(s)\n",
        "        return x\n",
        "\n",
        "#loss function with rel/abs Lp loss\n",
        "class LpLoss(object):\n",
        "    def __init__(self, d=2, p=2, size_average=True, reduction=True):\n",
        "        super(LpLoss, self).__init__()\n",
        "\n",
        "        #Dimension and Lp-norm type are postive\n",
        "        assert d > 0 and p > 0\n",
        "\n",
        "        self.d = d\n",
        "        self.p = p\n",
        "        self.reduction = reduction\n",
        "        self.size_average = size_average\n",
        "\n",
        "    def abs(self, x, y):\n",
        "        num_examples = x.size()[0]\n",
        "\n",
        "        #Assume uniform mesh\n",
        "        h = 1.0 / (x.size()[1] - 1.0)\n",
        "\n",
        "        all_norms = (h**(self.d/self.p))*torch.norm(x.view(num_examples,-1) - y.view(num_examples,-1), self.p, 1)\n",
        "\n",
        "        if self.reduction:\n",
        "            if self.size_average:\n",
        "                return torch.mean(all_norms)\n",
        "            else:\n",
        "                return torch.sum(all_norms)\n",
        "\n",
        "        return all_norms\n",
        "\n",
        "    def rel(self, x, y):\n",
        "        num_examples = x.size()[0]\n",
        "\n",
        "        diff_norms = torch.norm(x.reshape(num_examples,-1) - y.reshape(num_examples,-1), self.p, 1)\n",
        "        y_norms = torch.norm(y.reshape(num_examples,-1), self.p, 1)\n",
        "\n",
        "        if self.reduction:\n",
        "            if self.size_average:\n",
        "                return torch.mean(diff_norms/y_norms)\n",
        "            else:\n",
        "                return torch.sum(diff_norms/y_norms)\n",
        "\n",
        "        return diff_norms/y_norms\n",
        "\n",
        "    def __call__(self, x, y):\n",
        "        return self.rel(x, y)\n",
        "\n",
        "# A simple feedforward neural network\n",
        "class DenseNet(torch.nn.Module):\n",
        "    def __init__(self, layers, nonlinearity, out_nonlinearity=None, normalize=False):\n",
        "        super(DenseNet, self).__init__()\n",
        "\n",
        "        self.n_layers = len(layers) - 1\n",
        "\n",
        "        assert self.n_layers >= 1\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "\n",
        "        for j in range(self.n_layers):\n",
        "            self.layers.append(nn.Linear(layers[j], layers[j+1]))\n",
        "\n",
        "            if j != self.n_layers - 1:\n",
        "                if normalize:\n",
        "                    self.layers.append(nn.BatchNorm1d(layers[j+1]))\n",
        "\n",
        "                self.layers.append(nonlinearity())\n",
        "\n",
        "        if out_nonlinearity is not None:\n",
        "            self.layers.append(out_nonlinearity())\n",
        "\n",
        "    def forward(self, x):\n",
        "        for _, l in enumerate(self.layers):\n",
        "            x = l(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLgIy7iedqsR"
      },
      "source": [
        "# Model builder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzkTeyuZdu6V"
      },
      "source": [
        "#VIC this is the content of: https://github.com/zongyi-li/fourier_neural_operator/blob/master/fourier_2d_time.py\n",
        "# it needs to be udpated!\n",
        "# i made a small modification to the original code, please try to preserve it when updating it\n",
        "# the mod is highlighted by the following text #VIC-mod\n",
        "\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "################################################################\n",
        "# fourier layer\n",
        "################################################################\n",
        "\n",
        "class SpectralConv2d_fast(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, modes1, modes2):\n",
        "        super(SpectralConv2d_fast, self).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        2D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n",
        "        \"\"\"\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.modes1 = modes1 #Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
        "        self.modes2 = modes2\n",
        "\n",
        "        self.scale = (1 / (in_channels * out_channels))\n",
        "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
        "        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
        "\n",
        "    # Complex multiplication\n",
        "    def compl_mul2d(self, input, weights):\n",
        "        # (batch, in_channel, x,y ), (in_channel, out_channel, x,y) -> (batch, out_channel, x,y)\n",
        "        return torch.einsum(\"bixy,ioxy->boxy\", input, weights)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.shape[0]\n",
        "        #Compute Fourier coeffcients up to factor of e^(- something constant)\n",
        "        x_ft = torch.fft.rfft2(x)\n",
        "\n",
        "        # Multiply relevant Fourier modes\n",
        "        out_ft = torch.zeros(batchsize, self.out_channels,  x.size(-2), x.size(-1)//2 + 1, dtype=torch.cfloat, device=x.device)\n",
        "        out_ft[:, :, :self.modes1, :self.modes2] = \\\n",
        "            self.compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights1)\n",
        "        out_ft[:, :, -self.modes1:, :self.modes2] = \\\n",
        "            self.compl_mul2d(x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)\n",
        "\n",
        "        #Return to physical space\n",
        "        x = torch.fft.irfft2(out_ft, s=(x.size(-2), x.size(-1)))\n",
        "        return x\n",
        "\n",
        "class SimpleBlock2d(nn.Module):\n",
        "    def __init__(self, modes1, modes2, width, t_in):\n",
        "        super(SimpleBlock2d, self).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        The overall network. It contains 4 layers of the Fourier layer.\n",
        "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
        "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
        "            W defined by self.w; K defined by self.conv .\n",
        "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
        "        \n",
        "        input: the solution of the previous 10 timesteps + 2 locations (u(t-10, x, y), ..., u(t-1, x, y),  x, y)\n",
        "        input shape: (batchsize, x=64, y=64, c=12)\n",
        "        output: the solution of the next timestep\n",
        "        output shape: (batchsize, x=64, y=64, c=1)\n",
        "        \"\"\"\n",
        "\n",
        "        self.modes1 = modes1\n",
        "        self.modes2 = modes2\n",
        "        self.width = width\n",
        "        #self.fc0 = nn.Linear(12, self.width)\n",
        "        # input channel is 12: the solution of the previous 10 timesteps + 2 locations (u(t-10, x, y), ..., u(t-1, x, y),  x, y)\n",
        "        \n",
        "        #VIC-mod t_in is passed as parameter now, so that we can decide the number of input time steps\n",
        "        self.fc0 = nn.Linear(t_in+2, self.width)\n",
        "        # input channel: the solution of the previous t_in timesteps + 2 locations (u(t-10, x, y), ..., u(t-1, x, y),  x, y)\n",
        "\n",
        "\n",
        "        self.conv0 = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv1 = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv2 = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv3 = SpectralConv2d_fast(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.w0 = nn.Conv1d(self.width, self.width, 1)\n",
        "        self.w1 = nn.Conv1d(self.width, self.width, 1)\n",
        "        self.w2 = nn.Conv1d(self.width, self.width, 1)\n",
        "        self.w3 = nn.Conv1d(self.width, self.width, 1)\n",
        "        self.bn0 = torch.nn.BatchNorm2d(self.width)\n",
        "        self.bn1 = torch.nn.BatchNorm2d(self.width)\n",
        "        self.bn2 = torch.nn.BatchNorm2d(self.width)\n",
        "        self.bn3 = torch.nn.BatchNorm2d(self.width)\n",
        "\n",
        "        self.fc1 = nn.Linear(self.width, 128)\n",
        "        self.fc2 = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.shape[0]\n",
        "        size_x, size_y = x.shape[1], x.shape[2]\n",
        "\n",
        "        grid = self.get_grid(batchsize, size_x, size_y, x.device)\n",
        "        x = torch.cat((x, grid), dim=-1)\n",
        "        x = self.fc0(x)\n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "\n",
        "        x1 = self.conv0(x)\n",
        "        x2 = self.w0(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y)\n",
        "        x = self.bn0(x1 + x2)\n",
        "        x = F.relu(x)\n",
        "        x1 = self.conv1(x)\n",
        "        x2 = self.w1(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y)\n",
        "        x = self.bn1(x1 + x2)\n",
        "        x = F.relu(x)\n",
        "        x1 = self.conv2(x)\n",
        "        x2 = self.w2(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y)\n",
        "        x = self.bn2(x1 + x2)\n",
        "        x = F.relu(x)\n",
        "        x1 = self.conv3(x)\n",
        "        x2 = self.w3(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y)\n",
        "        x = self.bn3(x1 + x2)\n",
        "\n",
        "        x = x.permute(0, 2, 3, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def get_grid(self, batchsize, size_x, size_y, device):\n",
        "        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n",
        "        gridx = gridx.reshape(1, size_x, 1, 1).repeat([batchsize, 1, size_y, 1])\n",
        "        gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n",
        "        gridy = gridy.reshape(1, 1, size_y, 1).repeat([batchsize, size_x, 1, 1])\n",
        "        return torch.cat((gridx, gridy), dim=-1).to(device)\n",
        "\n",
        "class Net2d(nn.Module):\n",
        "    def __init__(self, modes, width, t_in):\n",
        "        super(Net2d, self).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        A wrapper function\n",
        "        \"\"\"\n",
        "\n",
        "        self.conv1 = SimpleBlock2d(modes, modes, width, t_in)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "    def count_params(self):\n",
        "        c = 0\n",
        "        for p in self.parameters():\n",
        "            c += reduce(operator.mul, list(p.size()))\n",
        "\n",
        "        return c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWQMCjxIgp0K"
      },
      "source": [
        "# Dataset Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-E0G_JAgsiz"
      },
      "source": [
        "#VIC leave this as it is\n",
        "\n",
        "def dataset_loader(dataset_name, dataset_path, n, win, stride=1, win_lim=-1) :\n",
        "  # get N, T, w and h from file name\n",
        "  datadetails = dataset_name.split(\"_\")\n",
        "  N = datadetails[2][1:]\n",
        "  N = int(N) # num of dataset entries\n",
        "  T = datadetails[3][1:]\n",
        "  T = int(T) # timesteps of each dataset entry\n",
        "  w = datadetails[4][1:]\n",
        "  w = int(w)\n",
        "  h = int(w)\n",
        "  # all the other parameters are dataset specific!\n",
        "\n",
        "  # to grab only a subset of the timesteps in each data entry\n",
        "  if win_lim != -1 and win_lim < T:\n",
        "    T = win_lim\n",
        "\n",
        "  # check that window size is smaller than number of timesteps per each data entry\n",
        "  assert (T >= win)  \n",
        "\n",
        "  # each entry in the dataset is now split in several trainig points, as big as T_in+T_out\n",
        "  #p_num = T-(win-1) # number of points per each dataset entry  \n",
        "  p_num = int( (T-win)/stride ) +1 # number of points per each dataset entry  \n",
        "  p_tot = N * p_num # all training points in dataset\n",
        "  print('Availble points in dataset: ', p_tot)\n",
        "  print('Points requested: ', n)\n",
        "  assert (p_tot >= n)  \n",
        "\n",
        "  # count number of checkpoints, their size and check for remainder file\n",
        "  dataset_full_path = dataset_path + dataset_name + '/'\n",
        "\n",
        "  files = os.listdir(dataset_full_path)\n",
        "  cp = len(files)\n",
        "  rem = 0\n",
        "\n",
        "  for name in files :\n",
        "    splitname = name.split(\"_\")\n",
        "    if splitname[-2] == 'rem' :\n",
        "      rem = 1\n",
        "      cp = cp-1\n",
        "      break\n",
        "\n",
        "  files = sorted(files) # order checkpoint files\n",
        "  cp_size = files[0].split(\"_\")[-1].split(\".\")[0] # read number of dataset entries in each checkpoint\n",
        "  cp_size = int(cp_size)\n",
        "  #cp_size = N//cp # number of dataset entries in each checkpoint\n",
        "  rem_size = 0 # number of dataset entries in remainder file [if any]\n",
        "  if rem > 0 :\n",
        "    rem_size = N - (cp*cp_size)\n",
        "\n",
        "  #print(N, T, w, h, cp, cp_size, rem, rem_size)\n",
        "\n",
        "  # prepare tensor where to load requested data points\n",
        "  u = torch.zeros(n, h, w, win)\n",
        "  #print(u.shape)\n",
        "\n",
        "  # actual sizes with moving window\n",
        "\n",
        "  cp_size_p = cp_size * p_num # number of points per each check point\n",
        "  rem_size_p = rem_size * p_num # number of points in remainder\n",
        "\n",
        "  # let's load\n",
        "\n",
        "  # check how many files we need to cover n points\n",
        "  full_files = n//(cp_size_p)\n",
        "  extra_datapoints = n%cp_size_p\n",
        "\n",
        "  extra_file_needed = extra_datapoints>0\n",
        "\n",
        "  print('Retrieved over', full_files, 'full files,', cp_size_p, 'points each')\n",
        "\n",
        "  # check that all numbers are fine\n",
        "  assert (full_files+extra_file_needed <= cp+rem)\n",
        "\n",
        "  \n",
        "  #print(files)\n",
        "  \n",
        "\n",
        "  # first load from files we will read completely \n",
        "  cnt = 0\n",
        "  for f in range(0,full_files) :\n",
        "    dataloader = MatReader(dataset_full_path+files[f])\n",
        "    uu = dataloader.read_field('u')\n",
        "    #print(f, files[f])\n",
        "    # unroll all entries with moving window\n",
        "    for e in range(0, cp_size) :\n",
        "      # window extracts p_num points from each dataset entry\n",
        "      #print('e', e, 'p_num', p_num)\n",
        "      for tt in range(0, p_num) :\n",
        "        #print('tt', tt)\n",
        "        t = tt*stride\n",
        "        #print('t', t)\n",
        "        u[cnt:cnt+1,...] = uu[e,:,:,t:t+win]\n",
        "        cnt = cnt+1\n",
        "\n",
        "  #print(cnt, extra_datapoints)\n",
        "  \n",
        "\n",
        "  # then load any possible remainder from a further file\n",
        "  if extra_datapoints>0 :\n",
        "    print('Plus', extra_datapoints, 'points from further file')\n",
        "    extra_entries = (extra_datapoints+0.5)//p_num # ceiling to be sure to have enough entries to unroll\n",
        "    dataloader = MatReader(dataset_full_path+files[full_files])\n",
        "    uu = dataloader.read_field('u')\n",
        "    entry = -1\n",
        "    while cnt < n :\n",
        "      entry = entry+1\n",
        "      for tt in range(0,p_num) :\n",
        "        t = tt*stride\n",
        "        u[cnt:cnt+1,...] = uu[entry,:,:,t:t+win] \n",
        "        cnt = cnt+1\n",
        "        if cnt >= n :\n",
        "          break\n",
        "\n",
        "  return u"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeHE_R1vd9de"
      },
      "source": [
        "# Settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dNGG72ZeABN",
        "outputId": "257a9988-5e1d-4d29-cc93-d4a4d638593c"
      },
      "source": [
        "#VIC leave this as it is\n",
        "# then you will be able to play around with the settings\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# editable simulation parameters\n",
        "ntrain = 15000\n",
        "ntest = 2000\n",
        "\n",
        "modes = 12\n",
        "width = 32\n",
        "\n",
        "batch_size = 20\n",
        "\n",
        "epochs = 500\n",
        "learning_rate = 0.0025\n",
        "scheduler_step = 100\n",
        "scheduler_gamma = 0.5\n",
        "\n",
        "print(epochs, learning_rate, scheduler_step, scheduler_gamma)\n",
        "\n",
        "T_in = 10\n",
        "T_out = 10\n",
        "# T_in+T_out is window size!\n",
        "\n",
        "win_stride = 1\n",
        "win_lim = -1 #(T_in+T_out)*200 #-1 for no limit\n",
        "\n",
        "# dataset\n",
        "dataset_name = 'iwe_d1_n1000_t50_s64_mu0@1_rho0@5_gamma1_xm2_xM32'\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "MODEL_ID = '2d_win'\n",
        "\n",
        "dataset_path = '/content/drive/My Drive/Colab Notebooks/neural_solver/wave_equation/irreducible/datasets/'\n",
        "\n",
        "# retrieve dataset details and check them\n",
        "splitname = dataset_name.split('_')\n",
        "\n",
        "DATASET = splitname[1]\n",
        "\n",
        "S = splitname[4]\n",
        "S = int(S[1:])\n",
        "\n",
        "mu = splitname[5][2:]\n",
        "rho = splitname[6][3:]\n",
        "gamma = splitname[7][5:]\n",
        "\n",
        "# prepare to save model\n",
        "model_name = 'iwe_m'+MODEL_ID+'_'+DATASET+'_n'+str(ntrain)+'+'+str(ntest)+'_e'+str(epochs)+'_m'+str(modes)+'_w'+ str(width)+'_ti'+str(T_in)+'_to'+str(T_out)+'_ws'+str(win_stride)+'_wl'+str(win_lim)+'_s'+str(S)+'_m'+mu+'_r'+rho+'_g'+gamma\n",
        "\n",
        "model_path = dataset_path[:-9]+'/models/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500 0.0025 100 0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPUr0mA2d3TA"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8htbNF3ro6Ky",
        "outputId": "a9e728d4-7670-4752-d6b2-0ab0d3dd9879"
      },
      "source": [
        "#VIC i think this needs only a minor update, i.e., removing the padding of the location\n",
        "\n",
        "t1 = default_timer()\n",
        "\n",
        "u = dataset_loader(dataset_name, dataset_path, ntrain+ntest, T_in+T_out, win_stride, win_lim)\n",
        "\n",
        "train_a = u[:ntrain,:,:,:T_in]\n",
        "train_u = u[:ntrain,:,:,T_in:T_in+T_out]\n",
        "\n",
        "ntest_start = ntrain\n",
        "test_a = u[ntest_start:ntest_start+ntest,:,:,:T_in]\n",
        "test_u = u[ntest_start:ntest_start+ntest:,:,:,T_in:T_in+T_out]\n",
        "\n",
        "#test_a = u[-ntest:,:,:,:T_in]\n",
        "#test_u = u[-ntest:,:,:,T_in:T_in+T_out]\n",
        "\n",
        "\n",
        "print(train_u.shape, test_u.shape)\n",
        "assert (S == train_u.shape[-2])\n",
        "assert (T_out == train_u.shape[-1])\n",
        "\n",
        "train_a = train_a.reshape(ntrain,S,S,T_in)\n",
        "test_a = test_a.reshape(ntest,S,S,T_in)\n",
        "\n",
        "#VIC should be removed\n",
        "# pad the location (x,y)\n",
        "# gridx = torch.tensor(np.linspace(0, 1, S), dtype=torch.float)\n",
        "# gridx = gridx.reshape(1, S, 1, 1).repeat([1, 1, S, 1])\n",
        "# gridy = torch.tensor(np.linspace(0, 1, S), dtype=torch.float)\n",
        "# gridy = gridy.reshape(1, 1, S, 1).repeat([1, S, 1, 1])\n",
        "\n",
        "# train_a = torch.cat((gridx.repeat([ntrain,1,1,1]), gridy.repeat([ntrain,1,1,1]), train_a), dim=-1)\n",
        "# test_a = torch.cat((gridx.repeat([ntest,1,1,1]), gridy.repeat([ntest,1,1,1]), test_a), dim=-1)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(train_a, train_u), batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_a, test_u), batch_size=batch_size, shuffle=False)\n",
        "\n",
        "t2 = default_timer()\n",
        "\n",
        "print('preprocessing finished, time used:', t2-t1, 's')\n",
        "print('train input shape:',train_a.shape, ' output shape: ', train_u.shape)    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Availble points in dataset:  31000\n",
            "Points requested:  17000\n",
            "Retrieved over 2 full files, 6200 points each\n",
            "Plus 4600 points from further file\n",
            "torch.Size([15000, 64, 64, 10]) torch.Size([2000, 64, 64, 10])\n",
            "preprocessing finished, time used: 27.508791729999984 s\n",
            "train input shape: torch.Size([15000, 64, 64, 10])  output shape:  torch.Size([15000, 64, 64, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y46kBR84qIsa"
      },
      "source": [
        "# Build and Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1x6rURfQqLCf",
        "outputId": "6aaf3320-3339-4489-ba2f-f581306c0861"
      },
      "source": [
        "#VIC this needs a couple of touch ups, as at the bottom of: https://github.com/zongyi-li/fourier_neural_operator/blob/master/fourier_2d_time.py\n",
        "# also, i made very minor changes to the original code, to make the logic clearer\n",
        "\n",
        "if torch.cuda.is_available() :\n",
        "  model = Net2d(modes, width, T_in).cuda()\n",
        "  device  = torch.device('cuda')\n",
        "else :\n",
        "  model = Net2d(modes, width, T_in)\n",
        "  device  = torch.device('cpu')\n",
        "\n",
        "\n",
        "print(model.count_params())\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step, gamma=scheduler_gamma)\n",
        "\n",
        "\n",
        "# myloss = LpLoss(size_average=False)\n",
        "\n",
        "#VIC these are not needed anymore\n",
        "# gridx = gridx.to(device)\n",
        "# gridy = gridy.to(device)\n",
        "\n",
        "\n",
        "\n",
        "myloss = LpLoss(size_average=False)\n",
        "step = 1\n",
        "for ep in range(epochs):\n",
        "    model.train()\n",
        "    t1 = default_timer()\n",
        "    train_l2_step = 0\n",
        "    train_l2_full = 0\n",
        "    for xx, yy in train_loader:\n",
        "        loss = 0\n",
        "        xx = xx.to(device)\n",
        "        yy = yy.to(device)\n",
        "\n",
        "        for t in range(0, T_out, step):\n",
        "            y = yy[..., t:t + step]\n",
        "            im = model(xx)\n",
        "            loss += myloss(im.reshape(batch_size, -1), y.reshape(batch_size, -1))\n",
        "\n",
        "            if t == 0:\n",
        "                pred = im\n",
        "            else:\n",
        "                pred = torch.cat((pred, im), -1)\n",
        "\n",
        "            xx = torch.cat((xx[..., step:], im), dim=-1)\n",
        "\n",
        "        train_l2_step += loss.item()\n",
        "        l2_full = myloss(pred.reshape(batch_size, -1), yy.reshape(batch_size, -1))\n",
        "        train_l2_full += l2_full.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    test_l2_step = 0\n",
        "    test_l2_full = 0\n",
        "    with torch.no_grad():\n",
        "        for xx, yy in test_loader:\n",
        "            loss = 0\n",
        "            xx = xx.to(device)\n",
        "            yy = yy.to(device)\n",
        "\n",
        "            for t in range(0, T_out, step):\n",
        "                y = yy[..., t:t + step]\n",
        "                im = model(xx)\n",
        "                loss += myloss(im.reshape(batch_size, -1), y.reshape(batch_size, -1))\n",
        "\n",
        "                if t == 0:\n",
        "                    pred = im\n",
        "                else:\n",
        "                    pred = torch.cat((pred, im), -1)\n",
        "\n",
        "                xx = torch.cat((xx[..., step:], im), dim=-1)\n",
        "\n",
        "            test_l2_step += loss.item()\n",
        "            test_l2_full += myloss(pred.reshape(batch_size, -1), yy.reshape(batch_size, -1)).item()\n",
        "\n",
        "    t2 = default_timer()\n",
        "    scheduler.step()\n",
        "    print(ep, t2 - t1, train_l2_step / ntrain / (T_out / step), train_l2_full / ntrain, test_l2_step / ntest / (T_out / step),\n",
        "          test_l2_full / ntest)\n",
        "    \n",
        "# add loss to name, with 4 decimals    \n",
        "final_training_loss = '{:.4f}'.format(test_l2_full / ntest)\n",
        "final_training_loss = final_training_loss.replace('.', '@')\n",
        "\n",
        "model_name = model_name+'_loss'+final_training_loss   \n",
        "model_full_path = model_path+model_name\n",
        "\n",
        "torch.save(model, model_full_path)\n",
        "\n",
        "#path_train_err = model_path+'results/'+model_name+'_train.txt'\n",
        "#path_test_err = model_path+'results/'+model_name+'_test.txt'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1188897\n",
            "0 197.23994342700001 1.4070204296875 1.4006416889190674 1.5094630561828613 1.5289709177017212\n",
            "1 196.75714442900005 0.7846910990397136 0.7844967452367146 0.8060891204833984 0.7991349730491638\n",
            "2 196.73732774400003 0.6192303081766763 0.6138920731226604 0.6789006214141846 0.6710995998382568\n",
            "3 196.619039102 0.5462406439208984 0.5417594748814901 0.618939658355713 0.6131355381011963\n",
            "4 196.510104179 0.5190478286234538 0.5136619705200195 0.6197721771240234 0.6123944118022918\n",
            "5 196.57225777999997 0.4968086539713542 0.4914577607790629 0.5611893363952637 0.5563551433086396\n",
            "6 196.59250822499985 0.47166127182006834 0.46585251592000326 0.5330247856140137 0.5285565721988678\n",
            "7 196.59861907599998 0.4577510762023926 0.4510818262418111 0.5234816263198853 0.5169168884754181\n",
            "8 196.60028257399995 0.4362749289703369 0.4286818249384562 0.5187018566131592 0.5133547606468201\n",
            "9 196.55137704799995 0.4118010817718506 0.4038964545249939 0.48086801280975344 0.4742453033924103\n",
            "10 196.65946733400006 0.401348237991333 0.39278934866587323 0.4682915449142456 0.4621712930202484\n",
            "11 196.70597963 0.3875372819773356 0.3788088473637899 0.44827669200897213 0.442156698346138\n",
            "12 196.47302253199996 0.37420839792887367 0.36524281873703 0.48115884323120117 0.4759563839435577\n",
            "13 196.43967613199993 0.37538202428181966 0.36649186175664267 0.44816086139678957 0.4407076299190521\n",
            "14 196.4240216229996 0.3658119799296061 0.35636909319559734 0.44004769821166995 0.43335783457756044\n",
            "15 196.81522654200035 0.3571784214528402 0.34814720808664956 0.4494436487197876 0.4444163861274719\n",
            "16 196.72548192799968 0.3391224096425374 0.3303415181795756 0.42885662155151366 0.422440495967865\n",
            "17 196.82787279600007 0.33618974047342937 0.3277387222290039 0.42849379482269284 0.4217410833835602\n",
            "18 196.694767685 0.34980039891560877 0.33982428102493284 0.4002296371459961 0.3929198172092438\n",
            "19 196.64593447800007 0.3351701395161947 0.3260821200052897 0.4155437791824341 0.40910516929626467\n",
            "20 196.8699572749997 0.31872372990926107 0.31057316573460897 0.4062246433258057 0.39981121122837066\n",
            "21 196.98692003199994 0.3298950191752116 0.3207061480204264 0.3980372667312622 0.3908354629278183\n",
            "22 196.96378598299998 0.31563274040222167 0.30678113134702045 0.3923889579772949 0.3851998646259308\n",
            "23 196.95147990199985 0.31291330388387045 0.3046857067426046 0.3998059083938599 0.39311607801914217\n",
            "24 196.9618950690001 0.3212673409525554 0.31249900620778404 0.427551813697815 0.4208589301109314\n",
            "25 196.9413852309999 0.3414371989695231 0.33062281408309935 0.4165231756210327 0.4085309016704559\n",
            "26 196.9504425390005 0.3090167645009359 0.3003248834292094 0.39425934829711917 0.3883800299167633\n",
            "27 196.9561906710005 0.32884322504679364 0.3187702691713969 0.3901374708175659 0.3831747490167618\n",
            "28 196.96486425500007 0.30208348281860353 0.29342421420415243 0.3876456848144531 0.3813682482242584\n",
            "29 197.0454140820002 0.29571462112426755 0.2874380170186361 0.38886517219543454 0.3821939095258713\n",
            "30 197.0876531799995 0.31929985041300457 0.31028695125579836 0.4172008907318115 0.4088983803987503\n",
            "31 197.0227845899999 0.32178431330362955 0.3104384901682536 0.3866658439636231 0.3789389917850494\n",
            "32 196.68715989599968 0.3022453946940104 0.2924579209645589 0.38588355178833006 0.37883079874515535\n",
            "33 196.75836651200007 0.2980526972961426 0.28939500754674274 0.3793908577919006 0.3730940895080566\n",
            "34 196.74116978199982 0.29921176429748536 0.2906374673048655 0.39233362960815427 0.38682705092430114\n",
            "35 196.72201355499965 0.29671823201497394 0.2881757701396942 0.37381736307144164 0.3681776123046875\n",
            "36 196.735840628 0.3239442003885905 0.31409838697115583 0.4211788455963135 0.4132905147075653\n",
            "37 196.7018204269998 0.30572287338256837 0.2961500876108805 0.3783065923690796 0.37228447771072387\n",
            "38 196.7271199400002 0.2969241911570231 0.28763274092674257 0.39848485889434815 0.3940715045928955\n",
            "39 196.69810487799987 0.3330460117085775 0.3217934262911479 0.38943784790039065 0.38166716396808625\n",
            "40 196.71919217899995 0.3169621365865072 0.3051423820813497 0.3786744674682617 0.37114321112632753\n",
            "41 196.69660439200015 0.3065415010579427 0.29508483940760294 0.38040256662368777 0.37295002365112306\n",
            "42 196.68062241000007 0.30938950271606447 0.2980471032142639 0.3931461904525757 0.38553390514850616\n",
            "43 196.687799198 0.3145522287750244 0.30319528846740723 0.4062119203567505 0.3998245940208435\n",
            "44 196.67123576999984 0.31046994875590006 0.2990094535509745 0.3753303686141968 0.367975666642189\n",
            "45 196.67481107499952 0.3022365158843994 0.2909674125353495 0.3790732429504394 0.3715026741027832\n",
            "46 196.63576529700003 0.31410871691385905 0.30334262342453006 0.4447400592803955 0.4363631830215454\n",
            "47 196.572723366 0.31969920130411783 0.3080660446802775 0.3821315073013306 0.3744121319055557\n",
            "48 196.5517749419996 0.30304240976969404 0.2917326644261678 0.37227942943573 0.3648693580627441\n",
            "49 196.5700096569999 0.29667080764770504 0.2855226869265238 0.3780381324768066 0.3697853536605835\n",
            "50 196.5520246340002 0.28666121976216635 0.2758582984129588 0.37780206813812256 0.3705000970363617\n",
            "51 196.62533349399928 0.29829308197021487 0.28721218207677207 0.38103472023010254 0.3733245342969894\n",
            "52 196.56536881600005 0.28727543741861983 0.2765467582066854 0.37379533405303955 0.3663315464258194\n",
            "53 196.49499651400038 0.30047606788635256 0.2894083368937174 0.3879265825271606 0.3803303793668747\n",
            "54 196.65852991700012 0.3030667031097412 0.29185517482757567 0.3841374368667603 0.3760729162693024\n",
            "55 196.41671875299835 0.28751315040588377 0.2769950771808624 0.37636268920898436 0.36863081812858584\n",
            "56 196.3845387300007 0.3070506117502848 0.2957098588784536 0.4014340188980102 0.39286282074451445\n",
            "57 196.45778801699998 0.29064636207580563 0.279941682656606 0.4007642967224121 0.3929883780479431\n",
            "58 196.42333638699893 0.28059646593729654 0.27033808040618895 0.3822935897827148 0.3743925657272339\n",
            "59 196.42359148600008 0.30293730359395343 0.29210678040186566 0.4106624406814575 0.4027191815376282\n",
            "60 196.3872048129997 0.29665124753316247 0.285366614262263 0.3842244197845459 0.3759854531288147\n",
            "61 196.37690476200078 0.27691017402648926 0.26642790087064105 0.3728018312454223 0.3643322443962097\n",
            "62 196.3279243550005 0.2842346457672119 0.27365441951751707 0.37745306663513184 0.3688241491317749\n",
            "63 196.08164410500103 0.2919654449971517 0.2813018836816152 0.38881535339355466 0.3809859071969986\n",
            "64 196.04074007999952 0.7896223097229004 0.7888648445129395 0.5776644119262695 0.5685305371284485\n",
            "65 196.24902111499978 0.45560496940612794 0.4445129541397095 0.45924390869140624 0.44886703705787656\n",
            "66 196.23019010700045 0.3787235368092855 0.36555408827463787 0.4228763204574585 0.4117997155189514\n",
            "67 196.10133710799892 0.32194630851745604 0.30990112628936767 0.4056314117431641 0.39546979904174806\n",
            "68 196.23435581299964 0.3061309860229492 0.2944822895685832 0.39657879791259765 0.38678868329524996\n",
            "69 196.27505488099996 0.28161418856302894 0.27097655227979023 0.3950905183792114 0.38529415011405943\n",
            "70 196.15256987000066 0.2886347758229574 0.2776941146214803 0.4127718446731567 0.4043442485332489\n",
            "71 196.16793137599961 0.283205418065389 0.2724170144557953 0.38526989307403564 0.37591623616218567\n",
            "72 196.18991827900027 0.29025249491373695 0.2793375109990438 0.3849053443908691 0.3763591313362122\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yphgOwKoKsHL"
      },
      "source": [
        "To avoid automatic runtime disconnection for inactivity [90 minutes]:\n",
        "\n",
        "_press ctlr+shift+i\n",
        "\n",
        "_then go to the console and type:\n",
        "\n",
        "```\n",
        "function ClickConnect(){\n",
        "  console.log(\"Connnect Clicked - Start\"); \n",
        "  document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click();\n",
        "  console.log(\"Connnect Clicked - End\"); \n",
        "};\n",
        "setInterval(ClickConnect, 60000)\n",
        "```\n",
        "\n",
        "\n",
        "This js code will click the \"Connect\" button [top right of Colab notebook] every minute...\n",
        "Maximum runtime life remains 12 hours\n",
        "\n",
        "Found here: https://stackoverflow.com/questions/57113226/how-to-prevent-google-colab-from-disconnecting?page=1&tab=votes#tab-top"
      ]
    }
  ]
}